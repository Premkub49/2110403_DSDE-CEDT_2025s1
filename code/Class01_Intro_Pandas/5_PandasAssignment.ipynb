{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OIom1X-v0TGc"
   },
   "source": [
    "# Assignment - Basic Pandas\n",
    "<sup>Created by Natawut Nupairoj, Department of Computer Engineering, Chulalongkorn University</sup>\n",
    "\n",
    "Using pandas to explore youtube trending data from GB (GBvideos.csv and GB_category_id.json) and answer the questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "id": "_ooeQeBn0TGf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RNyAGpWT0TGh"
   },
   "source": [
    "To simplify data retrieval process on Colab, we heck if we are in the Colab environment and download data files from a shared drive and save them in folder \"data\".\n",
    "\n",
    "For those using jupyter notebook on the local computer, you can read data directly assuming you save data in the folder \"data\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qro_9JWV0TGi",
    "outputId": "3e7f5c45-98ec-4160-bcc1-1697a048d29b"
   },
   "outputs": [],
   "outputs": [],
   "source": [
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "if IN_COLAB:\n",
    "    !wget https://github.com/kaopanboonyuen/2110446_DataScience_2021s2/raw/main/datasets/data.tgz -O data.tgz\n",
    "    !tar -xzvf data.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rkNi2LHT0TGj"
   },
   "source": [
    "## How many rows are there in the GBvideos.csv after removing duplications?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "id": "PFzYyW7V0TGj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before remove duplicate: 38916\n",
      "Rows after remove duplicate: 38745\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/GBvideos.csv')\n",
    "df_no_dup = df.drop_duplicates()\n",
    "print(f\"Rows before remove duplicate: {len(df)}\")\n",
    "print(f\"Rows after remove duplicate: {len(df_no_dup)}\")"
   ]
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before remove duplicate: 38916\n",
      "Rows after remove duplicate: 38745\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/GBvideos.csv')\n",
    "df_no_dup = df.drop_duplicates()\n",
    "print(f\"Rows before remove duplicate: {len(df)}\")\n",
    "print(f\"Rows after remove duplicate: {len(df_no_dup)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mSc2U7HJ0TGk"
   },
   "source": [
    "## How many VDO's that contain at least one record (row) of \"dislikes\" more than \"likes\"?  <font color=red>DO NOT group by the data and make sure that you count only unique title!</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "id": "Q0NF1dI40TGk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of VDO's that contain at least one record (row) of \"dislikes\" more than \"likes\" is 56\n"
     ]
    }
   ],
   "source": [
    "df_dis_more_like = df.loc[df['dislikes'] > df['likes'],\"title\"].unique()\n",
    "print(f\"Total of VDO's that contain at least one record (row) of \\\"dislikes\\\" more than \\\"likes\\\" is {len(df_dis_more_like)}\")"
   ]
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of VDO's that contain at least one record (row) of \"dislikes\" more than \"likes\" is 56\n"
     ]
    }
   ],
   "source": [
    "df_dis_more_like = df.loc[df['dislikes'] > df['likes'],\"title\"].unique()\n",
    "print(f\"Total of VDO's that contain at least one record (row) of \\\"dislikes\\\" more than \\\"likes\\\" is {len(df_dis_more_like)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oNxh-5CL0TGk"
   },
   "source": [
    "## How many VDO that are trending on 22 Jan 2018 with comments more than 10,000 comments?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "id": "07-y5sNw0TGl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of VDO that are trending on 22 Jan 2018 with comments more than 10,000 comments is 28\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total of VDO that are trending on 22 Jan 2018 with comments more than 10,000 comments is {len(df[(df['comment_count']>10000)  & (df['trending_date'].str.contains('18.22.01'))])}\")"
   ]
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of VDO that are trending on 22 Jan 2018 with comments more than 10,000 comments is 28\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total of VDO that are trending on 22 Jan 2018 with comments more than 10,000 comments is {len(df[(df['comment_count']>10000)  & (df['trending_date'].str.contains('18.22.01'))])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jnBQwfD70TGl"
   },
   "source": [
    "## Which date that has the minimum average number of comments per VDO?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        26\n",
       "1        24\n",
       "2        10\n",
       "3        17\n",
       "4        25\n",
       "         ..\n",
       "38911    10\n",
       "38912    10\n",
       "38913    10\n",
       "38914    24\n",
       "38915    10\n",
       "Name: category_id, Length: 38916, dtype: int64"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "id": "KIDZyavc0TGl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The date that has the minimum average number of comments per VDO is 2017-11-15\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "df_group_publish = df.groupby(by=['trending_date'])\n",
    "df_date_min_avg = df_group_publish['comment_count'].mean().idxmin()\n",
    "print(f\"The date that has the minimum average number of comments per VDO is {datetime.strptime(df_date_min_avg, '%y.%d.%m').date()}\")"
   ]
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The date that has the minimum average number of comments per VDO is 2017-11-15\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "df_group_publish = df.groupby(by=['trending_date'])\n",
    "df_date_min_avg = df_group_publish['comment_count'].mean().idxmin()\n",
    "print(f\"The date that has the minimum average number of comments per VDO is {datetime.strptime(df_date_min_avg, '%y.%d.%m').date()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wL7iTiic0TGl"
   },
   "source": [
    "## Compare \"Sports\" and \"Comady\", how many days that there are more total daily views of VDO in \"Sports\" category than in \"Comady\" category?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "id": "UIzvYqdA0TGm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total days that there are more total daily views of VDO in \"Sports\" category than in \"Comedy\" category is 49\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pandas import json_normalize\n",
    "with open(\"data/GB_category_id.json\") as file:\n",
    "    json_data = json.load(file)\n",
    "df_category_id = json_normalize(json_data, record_path=['items'])\n",
    "sports_id = int(df_category_id.loc[(df_category_id[\"snippet.title\"] == \"Sports\") & (df_category_id[\"snippet.assignable\"]),\"id\"].iloc[0])\n",
    "comedy_id = int(df_category_id.loc[(df_category_id[\"snippet.title\"] == \"Comedy\") & (df_category_id[\"snippet.assignable\"]),\"id\"].iloc[0])\n",
    "df_sports = df[df['category_id'] == sports_id]\n",
    "df_comedy = df[df['category_id'] == comedy_id]\n",
    "df_sports_sum = df_sports.groupby(by=['trending_date'],as_index=False)['views'].sum()\n",
    "df_comedy_sum = df_comedy.groupby(by=['trending_date'],as_index=False)['views'].sum()\n",
    "df_sports_comp_comedy = pd.merge(df_sports_sum, df_comedy_sum, on='trending_date', how='outer')\n",
    "df_sports_comp_comedy = df_sports_comp_comedy[((df_sports_comp_comedy['trending_date'].notna()) & ((df_sports_comp_comedy['views_y'].isna()) | (df_sports_comp_comedy['views_x'] > df_sports_comp_comedy['views_y'])))]\n",
    "print(f\"Total days that there are more total daily views of VDO in \\\"Sports\\\" category than in \\\"Comedy\\\" category is {len(df_sports_comp_comedy)}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dsde-cedt",
   "display_name": "dsde-cedt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
   "version": "3.10.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
