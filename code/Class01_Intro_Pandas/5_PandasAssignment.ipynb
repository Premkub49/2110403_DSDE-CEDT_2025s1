{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OIom1X-v0TGc"
   },
   "source": [
    "# Assignment - Basic Pandas\n",
    "<sup>Created by Natawut Nupairoj, Department of Computer Engineering, Chulalongkorn University</sup>\n",
    "\n",
    "Using pandas to explore youtube trending data from GB (GBvideos.csv and GB_category_id.json) and answer the questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_ooeQeBn0TGf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RNyAGpWT0TGh"
   },
   "source": [
    "To simplify data retrieval process on Colab, we heck if we are in the Colab environment and download data files from a shared drive and save them in folder \"data\".\n",
    "\n",
    "For those using jupyter notebook on the local computer, you can read data directly assuming you save data in the folder \"data\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qro_9JWV0TGi",
    "outputId": "3e7f5c45-98ec-4160-bcc1-1697a048d29b"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "if IN_COLAB:\n",
    "    !wget https://github.com/kaopanboonyuen/2110446_DataScience_2021s2/raw/main/datasets/data.tgz -O data.tgz\n",
    "    !tar -xzvf data.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rkNi2LHT0TGj"
   },
   "source": [
    "## How many rows are there in the GBvideos.csv after removing duplications?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "PFzYyW7V0TGj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before remove duplicate: 38916\n",
      "Rows after remove duplicate: 38745\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/GBvideos.csv')\n",
    "df_no_dup = df.drop_duplicates()\n",
    "print(f\"Rows before remove duplicate: {len(df)}\")\n",
    "print(f\"Rows after remove duplicate: {len(df_no_dup)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mSc2U7HJ0TGk"
   },
   "source": [
    "## How many VDO's that contain at least one record (row) of \"dislikes\" more than \"likes\"?  <font color=red>DO NOT group by the data and make sure that you count only unique title!</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Q0NF1dI40TGk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of VDO's that contain at least one record (row) of \"dislikes\" more than \"likes\" is 56\n"
     ]
    }
   ],
   "source": [
    "df_dis_more_like = df.loc[df['dislikes'] > df['likes'],\"title\"].unique()\n",
    "print(f\"Total of VDO's that contain at least one record (row) of \\\"dislikes\\\" more than \\\"likes\\\" is {len(df_dis_more_like)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oNxh-5CL0TGk"
   },
   "source": [
    "## How many VDO that are trending on 22 Jan 2018 with comments more than 10,000 comments?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "07-y5sNw0TGl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of VDO that are trending on 22 Jan 2018 with comments more than 10,000 comments is 28\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total of VDO that are trending on 22 Jan 2018 with comments more than 10,000 comments is {len(df[(df['comment_count']>10000)  & (df['trending_date'].str.contains('18.22.01'))])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jnBQwfD70TGl"
   },
   "source": [
    "## Which date that has the minimum average number of comments per VDO?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        26\n",
       "1        24\n",
       "2        10\n",
       "3        17\n",
       "4        25\n",
       "         ..\n",
       "38911    10\n",
       "38912    10\n",
       "38913    10\n",
       "38914    24\n",
       "38915    10\n",
       "Name: category_id, Length: 38916, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "KIDZyavc0TGl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The date that has the minimum average number of comments per VDO is 2017-11-15\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "df_group_publish = df.groupby(by=['trending_date'])\n",
    "df_date_min_avg = df_group_publish['comment_count'].mean().idxmin()\n",
    "print(f\"The date that has the minimum average number of comments per VDO is {datetime.strptime(df_date_min_avg, '%y.%d.%m').date()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wL7iTiic0TGl"
   },
   "source": [
    "## Compare \"Sports\" and \"Comady\", how many days that there are more total daily views of VDO in \"Sports\" category than in \"Comady\" category?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "UIzvYqdA0TGm"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trending_date</th>\n",
       "      <th>views_x</th>\n",
       "      <th>views_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.01.12</td>\n",
       "      <td>9879808</td>\n",
       "      <td>10889970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.02.12</td>\n",
       "      <td>10856461</td>\n",
       "      <td>13302391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.03.12</td>\n",
       "      <td>10875249</td>\n",
       "      <td>14259944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.04.12</td>\n",
       "      <td>11399173</td>\n",
       "      <td>16617431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.05.12</td>\n",
       "      <td>11261410</td>\n",
       "      <td>19089597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>18.30.04</td>\n",
       "      <td>15114095</td>\n",
       "      <td>17802688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>18.30.05</td>\n",
       "      <td>5153521</td>\n",
       "      <td>16427316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>18.31.01</td>\n",
       "      <td>8431519</td>\n",
       "      <td>14840766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>18.31.03</td>\n",
       "      <td>22546308</td>\n",
       "      <td>21528161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>18.31.05</td>\n",
       "      <td>6343358</td>\n",
       "      <td>16743398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    trending_date   views_x   views_y\n",
       "0        17.01.12   9879808  10889970\n",
       "1        17.02.12  10856461  13302391\n",
       "2        17.03.12  10875249  14259944\n",
       "3        17.04.12  11399173  16617431\n",
       "4        17.05.12  11261410  19089597\n",
       "..            ...       ...       ...\n",
       "200      18.30.04  15114095  17802688\n",
       "201      18.30.05   5153521  16427316\n",
       "202      18.31.01   8431519  14840766\n",
       "203      18.31.03  22546308  21528161\n",
       "204      18.31.05   6343358  16743398\n",
       "\n",
       "[205 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from pandas import json_normalize\n",
    "with open(\"data/GB_category_id.json\") as file:\n",
    "    json_data = json.load(file)\n",
    "df_category_id = json_normalize(json_data, record_path=['items'])\n",
    "sports_id = int(df_category_id.loc[(df_category_id[\"snippet.title\"] == \"Sports\") & (df_category_id[\"snippet.assignable\"]),\"id\"].iloc[0])\n",
    "comedy_id = int(df_category_id.loc[(df_category_id[\"snippet.title\"] == \"Comedy\") & (df_category_id[\"snippet.assignable\"]),\"id\"].iloc[0])\n",
    "df_sports = df[df['category_id'] == sports_id]\n",
    "df_comedy = df[df['category_id'] == comedy_id]\n",
    "df_sports_sum = df_sports.groupby(by=['trending_date'],as_index=False)['views'].sum()\n",
    "df_comedy_sum = df_comedy.groupby(by=['trending_date'],as_index=False)['views'].sum()\n",
    "df_sports_comp_comedy = pd.merge(df_sports_sum, df_comedy_sum, on='trending_date', how='outer')\n",
    "df_sports_comp_comedy\n",
    "# df_sports_comp_comedy = df_sports_comp_comedy[((df_sports_comp_comedy['trending_date'].notna()) & ((df_sports_comp_comedy['views_y'].isna()) | (df_sports_comp_comedy['views_x'] > df_sports_comp_comedy['views_y'])))]\n",
    "# print(f\"Total days that there are more total daily views of VDO in \\\"Sports\\\" category than in \\\"Comedy\\\" category is {len(df_sports_comp_comedy)}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dsde-cedt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
